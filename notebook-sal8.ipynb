{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":107555,"databundleVersionId":13033998,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1>Cloning GitHub Repo</h1>","metadata":{}},{"cell_type":"code","source":"#----------Cloning GitHub Repo------------\n!git clone https://github.com/SimoneRoma21/PKMN_VictoryBinaryClassification.git\n#!git pull","metadata":{"execution":{"iopub.status.busy":"2025-11-15T10:16:34.848444Z","iopub.execute_input":"2025-11-15T10:16:34.848703Z","iopub.status.idle":"2025-11-15T10:16:39.260606Z","shell.execute_reply.started":"2025-11-15T10:16:34.848674Z","shell.execute_reply":"2025-11-15T10:16:39.259184Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Cloning into 'PKMN_VictoryBinaryClassification'...\nremote: Enumerating objects: 658, done.\u001b[K\nremote: Counting objects: 100% (288/288), done.\u001b[K\nremote: Compressing objects: 100% (196/196), done.\u001b[K\nremote: Total 658 (delta 120), reused 248 (delta 92), pack-reused 370 (from 1)\u001b[K\nReceiving objects: 100% (658/658), 32.42 MiB | 19.96 MiB/s, done.\nResolving deltas: 100% (373/373), done.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"#---------Appending the right path----------\nimport sys\n\n# Make sure to replace the repository folder with the actual folder name\nrepo_path = ['/kaggle/working/PKMN_VictoryBinaryClassification/py','/kaggle/working/PKMN_VictoryBinaryClassification/data']\nif repo_path not in sys.path:\n    sys.path.append(repo_path)\nprint(sys.path)\n\n%cd /kaggle/working/PKMN_VictoryBinaryClassification/py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T21:36:04.850942Z","iopub.execute_input":"2025-11-13T21:36:04.851314Z","iopub.status.idle":"2025-11-13T21:36:04.860461Z","shell.execute_reply.started":"2025-11-13T21:36:04.851281Z","shell.execute_reply":"2025-11-13T21:36:04.859622Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<H1>Imports</H1>","metadata":{}},{"cell_type":"code","source":"import json\nimport pandas as pd\nfrom dataset.dataset_construction import Feature, FeaturePipeline\nfrom dataset.csv_utilities import *\nfrom dataset.extract_utilities import *\nfrom ModelTrainer import ModelTrainer\nfrom sklearn.model_selection import train_test_split,GridSearchCV\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestClassifier, StackingClassifier\nfrom xgboost import XGBClassifier\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T21:36:17.723232Z","iopub.execute_input":"2025-11-13T21:36:17.723547Z","iopub.status.idle":"2025-11-13T21:36:19.607335Z","shell.execute_reply.started":"2025-11-13T21:36:17.723522Z","shell.execute_reply":"2025-11-13T21:36:19.606282Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<H1>Feature Selected</H1>\n\nThese are the feature that we're gonna use for the three submissions. So scores are computed on the same features.\nIn these feature you can see:\n- Stats features: literally the mean of the stats a pokemon has\n- Ratio on stats: we use two stats (like atk,def, spe, spa, spd, hp) to create ratios\n- Differential stats: we calculate the differences of the stats (like atk,def, spe, spa, spd, hp) between two moments, the start of the game and after the 30 turns\n- Info features: describes values that can be seen in battles like number of pokemon alive, number of switches that the players do, etc.\n- Status features: counts the pokemon of each team affected by battle statuses like poison, paralysis, burned, etc.\n- Moves features: counts the pokemon of each team that have certain moves in their moveset. ","metadata":{}},{"cell_type":"code","source":"selected_features = [\n        \n        #------Stats Features---------#\n        Feature.P1_FINAL_TEAM_HP, \n        Feature.P2_FINAL_TEAM_HP, \n        Feature.MEAN_SPE_LAST, \n        Feature.MEAN_HP_LAST, \n        Feature.MEAN_ATK_LAST, \n        Feature.MEAN_SPA_LAST, \n        Feature.MEAN_STATS_LAST, \n        Feature.MEAN_CRIT,\n\n        #------Ratio on Stats Features--------#\n        Feature.HP_BULK_RATIO,\n        Feature.SPE_ATK_RATIO,\n        Feature.OFF_DEF_RATIO,\n        Feature.OFF_SPAD_RATIO,\n\n        #-------Differential Features on Stats---#\n        Feature.HP_TREND_DIFF,\n        Feature.ATK_TREND_DIFF,\n        Feature.SPA_TREND_DIFF,\n        Feature.SPE_TREND_DIFF,\n    \n        #---Feature Infos During Battle----#\n        Feature.P1_ALIVE_PKMN, \n        Feature.P2_ALIVE_PKMN, \n        Feature.P1_SWITCHES_COUNT, \n        Feature.P2_SWITCHES_COUNT,\n    \n        Feature.P1_AVG_HP_WHEN_SWITCHING, \n        Feature.P2_AVG_HP_WHEN_SWITCHING, \n        Feature.P1_MAX_DEBUFF_RECEIVED,\n        Feature.P2_MAX_DEBUFF_RECEIVED,\n        Feature.P1_AVG_MOVE_POWER, \n        Feature.P2_AVG_MOVE_POWER, \n        Feature.AVG_MOVE_POWER_DIFFERENCE, \n        Feature.P1_OFFENSIVE_RATIO, \n        Feature.P2_OFFENSIVE_RATIO, \n        Feature.OFFENSIVE_RATIO_DIFFERENCE, \n        Feature.P1_MOVED_FIRST_COUNT, \n        Feature.P2_MOVED_FIRST_COUNT, \n        Feature.SPEED_ADVANTAGE_RATIO, \n\n        #----Feature Status of Pokemons----#\n        Feature.P1_FROZEN_PKMN, \n        Feature.P2_FROZEN_PKMN, \n        Feature.P1_PARALIZED_PKMN, \n        Feature.P2_PARALIZED_PKMN, \n        Feature.P1_SLEEP_PKMN, \n        Feature.P2_SLEEP_PKMN, \n        Feature.P1_POISON_PKMN, \n        Feature.P2_POISON_PKMN,  \n        Feature.P1_BURNED_PKMN, \n        Feature.P2_BURNED_PKMN, \n        \n        #----Feature Pokemon Moves----#\n        Feature.P1_PKMN_REFLECT, \n        Feature.P2_PKMN_REFLECT, \n        Feature.P1_PKMN_REST, \n        Feature.P2_PKMN_REST, \n        Feature.P1_PKMN_EXPLOSION, \n        Feature.P2_PKMN_EXPLOSION, \n        Feature.P1_PKMN_THUNDERWAVE, \n        Feature.P2_PKMN_THUNDERWAVE, \n        Feature.P1_PKMN_RECOVER, \n        Feature.P2_PKMN_RECOVER, \n        Feature.P1_PKMN_TOXIC, \n        Feature.P2_PKMN_TOXIC, \n        Feature.P1_PKMN_FIRESPIN, \n        Feature.P2_PKMN_FIRESPIN,          \n    ]\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T21:36:20.896497Z","iopub.execute_input":"2025-11-13T21:36:20.896972Z","iopub.status.idle":"2025-11-13T21:36:20.905265Z","shell.execute_reply.started":"2025-11-13T21:36:20.896943Z","shell.execute_reply":"2025-11-13T21:36:20.904230Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h1>Main code for training and evaluation</h1>\n","metadata":{}},{"cell_type":"markdown","source":"### First Subsmission\n\nThis submission uses GridSearch on a LogisticRegression with 0.2/0.8 ratio for test/train. CrossValidation uses 5 fold and is applied by the GridSearch itself. On the public the submission is called first_submission.csv. The csv is also saved in \"kaggle/working\" as first_submission.csv if the cell is ran. Locally we have 84.89 training accuracy and 85.55 evaluation accuracy. On the public we get 84.93. The kaggle produce 84.85 training accuracy and 85.50 evaluation accuracy, uploading the csv we get 84.86 on the public. ","metadata":{}},{"cell_type":"code","source":"def evaluate_test_set(trainer: ModelTrainer, feature_list: list, test_file_path: str):\n\n    feature_pipeline = FeaturePipeline(feature_list, cache_dir=\"../data/test_feature_cache\")\n\n    print(\"\\nLoading test data...\")\n    test_data = []\n    with open(test_file_path, 'r') as f:\n        for line in f:\n            test_data.append(json.loads(line))\n\n    # Extract features from test set\n    print(\"\\nExtracting features from test data...\")\n    test_df = feature_pipeline.extract_features(test_data, show_progress=True)\n\n    X_test = test_df.drop(['battle_id'], axis=1, errors='ignore')\n\n    # Predict on test set\n    predictions = trainer.predict(X_test)\n\n    submission = pd.DataFrame({\n        'battle_id': test_df['battle_id'],\n        'player_won': predictions\n    })\n    submission.to_csv('/kaggle/working/first_submission.csv', index=False)\n\n\nfeature_pipeline = FeaturePipeline(selected_features)\n\ntrain_file_path = '/kaggle/input/fds-pokemon-battles-prediction-2025/train.jsonl'\ntest_file_path = '/kaggle/input/fds-pokemon-battles-prediction-2025/test.jsonl'\ntrain_out_path=\"predict_csv/train_features_extracted.csv\"\n\nprint(\"Loading training data...\")\ntrain_data = []\nwith open(train_file_path, 'r') as f:\n    for line in f:\n        train_data.append(json.loads(line))\n\n# Extract the features for train_set\nprint(\"\\nExtracting features from training data...\")\ntrain_df = feature_pipeline.extract_features(train_data)\nprint(\"\\nTraining features preview:\")\nprint(train_df.head())\n\n# Save dataset in a CSV file\ntrain_df.to_csv(train_out_path, index=False)\n\n#---------------Model Training and Evaluation Code------------------------\n\n# Remove row 4877 from the train dataset\ntrain_df = train_df.drop(index=4877)\nX_train = train_df.drop(['battle_id', 'player_won'], axis=1)\ny_train = train_df['player_won']\n\n\nX_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n\n# Pipeline with scaler and model\nprint(\"\\nCreating pipeline with RobustScaler and LogisticRegression...\")\npipeline = Pipeline([\n    ('scaler',RobustScaler()),\n    ('classifier', LogisticRegression(random_state=42, max_iter=2000)),\n])\n\n#Grid Search for Logistic Regression \nparam_grid={\n     'classifier__C':[0.01,0.1,1,10,100],\n     'classifier__penalty': ['l1','l2'],\n     'classifier__solver':['liblinear','saga'],\n     'classifier__max_iter':[1000,2000]\n}\n\ngrid_logreg = GridSearchCV(\n    estimator=pipeline,\n    param_grid=param_grid,\n    scoring='roc_auc',\n    # scoring='accuracy',\n    n_jobs=-1,  \n    cv=5,            # 5-fold cross-validation, more on this later\n    refit=True,      # retrain the best model on the full training set\n    return_train_score=True\n)\n\n\ntrainer = ModelTrainer(grid_logreg)\ntrainer.train(X_tr, y_tr)\ntrainer.evaluate(X_val, y_val)\n\nprint(\"Best CV score:\", grid_logreg.best_score_)\nprint(\"Best params:\", grid_logreg.best_params_)\n\n\n# ------------------ Evaluate on Test Set -----------------\nevaluate_test_set(trainer, selected_features, test_file_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T21:36:24.249512Z","iopub.execute_input":"2025-11-13T21:36:24.249858Z","iopub.status.idle":"2025-11-13T21:44:53.231439Z","shell.execute_reply.started":"2025-11-13T21:36:24.249831Z","shell.execute_reply":"2025-11-13T21:44:53.230307Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Second Subsmission\n\nThis submission uses GridSearch on a LogisticRegression with 0.1/0.9 ratio for test/train. CrossValidation uses 5 fold and is applied by the GridSearch itself. On the public the submission is called second_submission.csv. The csv is also saved in \"kaggle/working\" as second_submission.csv if the cell is ran. Locally we have 85.02 training accuracy and 85.40 evaluation accuracy. On the public we get 84.73. The kaggle produce 85.04 training accuracy and 85.30 evaluation accuracy, uploading the csv we get 84.73 on the public. \n","metadata":{}},{"cell_type":"code","source":"def evaluate_test_set(trainer: ModelTrainer, feature_list: list, test_file_path: str):\n\n    feature_pipeline = FeaturePipeline(feature_list, cache_dir=\"../data/test_feature_cache\")\n\n    print(\"\\nLoading test data...\")\n    test_data = []\n    with open(test_file_path, 'r') as f:\n        for line in f:\n            test_data.append(json.loads(line))\n\n    # Extract features from test set\n    print(\"\\nExtracting features from test data...\")\n    test_df = feature_pipeline.extract_features(test_data, show_progress=True)\n\n    X_test = test_df.drop(['battle_id'], axis=1, errors='ignore')\n\n    # Predict on test set\n    predictions = trainer.predict(X_test)\n\n    submission = pd.DataFrame({\n        'battle_id': test_df['battle_id'],\n        'player_won': predictions\n    })\n    submission.to_csv('/kaggle/working/second_submission.csv', index=False)\n\n\n\nfeature_pipeline = FeaturePipeline(selected_features)\n\ntrain_file_path = '/kaggle/input/fds-pokemon-battles-prediction-2025/train.jsonl'\ntest_file_path = '/kaggle/input/fds-pokemon-battles-prediction-2025/test.jsonl'\ntrain_out_path=\"predict_csv/train_features_extracted.csv\"\n\nprint(\"Loading training data...\")\ntrain_data = []\nwith open(train_file_path, 'r') as f:\n    for line in f:\n        train_data.append(json.loads(line))\n\n# Extract the features for train_set\nprint(\"\\nExtracting features from training data...\")\ntrain_df = feature_pipeline.extract_features(train_data)\nprint(\"\\nTraining features preview:\")\nprint(train_df.head())\n\n# Save dataset in a CSV file\ntrain_df.to_csv(train_out_path, index=False)\n\n#---------------Model Training and Evaluation Code------------------------\n\n# Remove row 4877 from the train dataset\ntrain_df = train_df.drop(index=4877)\nX_train = train_df.drop(['battle_id', 'player_won'], axis=1)\ny_train = train_df['player_won']\n\n\nX_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n\n# Pipeline with scaler and model\nprint(\"\\nCreating pipeline with RobustScaler and LogisticRegression...\")\npipeline = Pipeline([\n    ('scaler',RobustScaler()),\n    ('classifier', LogisticRegression(random_state=42, max_iter=2000)),\n])\n\n#Grid Search for Logistic Regression \nparam_grid={\n     'classifier__C':[0.01,0.1,1,10,100],\n     'classifier__penalty': ['l1','l2'],\n     'classifier__solver':['liblinear','saga'],\n     'classifier__max_iter':[1000,2000]\n}\n\ngrid_logreg = GridSearchCV(\n    estimator=pipeline,\n    param_grid=param_grid,\n    scoring='roc_auc',\n    # scoring='accuracy',\n    n_jobs=-1,  \n    cv=5,            # 5-fold cross-validation, more on this later\n    refit=True,      # retrain the best model on the full training set\n    return_train_score=True\n)\n\n\ntrainer = ModelTrainer(grid_logreg)\ntrainer.train(X_tr, y_tr)\ntrainer.evaluate(X_val, y_val)\n\nprint(\"Best CV score:\", grid_logreg.best_score_)\nprint(\"Best params:\", grid_logreg.best_params_)\n\n\n# ------------------ Evaluate on Test Set -----------------\n\nevaluate_test_set(trainer, selected_features, test_file_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T21:47:08.208551Z","iopub.execute_input":"2025-11-13T21:47:08.209010Z","iopub.status.idle":"2025-11-13T21:56:29.094964Z","shell.execute_reply.started":"2025-11-13T21:47:08.208976Z","shell.execute_reply":"2025-11-13T21:56:29.093978Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Third Subsmission\nThis submission uses ModelStacking where the base estimators are LogisticRegression, SGDClassifier, XGBClassifier and RandomForest. We used 2 linear models and 2 non-linear models to combine the advantages of both types. Each of the base estimators has been fine-tuned separately using GridSearchCV on the same training data before being included in the stacking ensemble. The meta model is LogisticRegression. Split ratio is 0.2/0.8 for test/train. CrossValidation uses 5 fold and is applied by the GridSearch itself. On the public the submission is called third_submission.csv. The csv is also saved in \"kaggle/working\" as second_submission.csv if the cell is ran. The kaggle produce 85.14 training accuracy and 85.45 evaluation accuracy, uploading the csv we get 84.46 on the public.  ","metadata":{}},{"cell_type":"code","source":"def evaluate_test_set(trainer: ModelTrainer, feature_list: list, test_file_path: str):\n\n    feature_pipeline = FeaturePipeline(feature_list, cache_dir=\"../data/test_feature_cache\")\n\n    print(\"\\nLoading test data...\")\n    test_data = []\n    with open(test_file_path, 'r') as f:\n        for line in f:\n            test_data.append(json.loads(line))\n\n    # Extract features from test set\n    print(\"\\nExtracting features from test data...\")\n    test_df = feature_pipeline.extract_features(test_data, show_progress=True)\n\n    X_test = test_df.drop(['battle_id'], axis=1, errors='ignore')\n\n    # Predict on test set\n    predictions = trainer.predict(X_test)\n\n    submission = pd.DataFrame({\n        'battle_id': test_df['battle_id'],\n        'player_won': predictions\n    })\n    submission.to_csv('/kaggle/working/third_submission.csv', index=False)\n\nfeature_pipeline = FeaturePipeline(selected_features)\n\ntrain_file_path = '/kaggle/input/fds-pokemon-battles-prediction-2025/train.jsonl'\ntest_file_path = '/kaggle/input/fds-pokemon-battles-prediction-2025/test.jsonl'\ntrain_out_path=\"predict_csv/train_features_extracted.csv\"\n\nprint(\"Loading training data...\")\ntrain_data = []\nwith open(train_file_path, 'r') as f:\n    for line in f:\n        train_data.append(json.loads(line))\n\n# Extract the features for train_set\nprint(\"\\nExtracting features from training data...\")\ntrain_df = feature_pipeline.extract_features(train_data)\nprint(\"\\nTraining features preview:\")\nprint(train_df.head())\n\n# Save dataset in a CSV file\ntrain_df.to_csv(train_out_path, index=False)\n\n#---------------Model Training and Evaluation Code------------------------\n\n# Remove row 4877 from the train dataset\ntrain_df = train_df.drop(index=4877)\nX_train = train_df.drop(['battle_id', 'player_won'], axis=1)\ny_train = train_df['player_won']\n\n\nX_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n\n# Pipelines: Scaling only the linear models\npipe_lr = Pipeline([\n    ('scaler', RobustScaler()),\n    ('lr', LogisticRegression(max_iter=1000,C=1,penalty='l1',solver='liblinear',random_state=42))\n])\n\npipe_sgd = Pipeline([\n    ('scaler', RobustScaler()),\n    ('sgd', SGDClassifier(\n        loss='modified_huber',\n        penalty='l1',\n        alpha=0.001,\n        learning_rate='adaptive',\n        eta0=0.01,\n        max_iter=1000,\n        tol=0.0001,\n        random_state=42\n    ))\n])\n\n# Tree and Boosting\nxgb = XGBClassifier(\n    eval_metric='logloss',\n    random_state=42,\n    colsample_bytree=0.8,\n    gamma=0.3,\n    learning_rate=0.05,\n    max_depth=3,\n    min_child_weight=5,\n    n_estimators=400,\n    reg_alpha=0,\n    reg_lambda=2,\n    subsample=0.8\n    )\n\nrf = RandomForestClassifier(\n    random_state=42, bootstrap=True,\n    max_depth=12, max_features='sqrt',\n    min_samples_leaf=3, min_samples_split=5, n_estimators=300\n    )\n\n# Base estimators\nbase_estimators = [\n    ('lr', pipe_lr),\n    ('xgb', xgb),\n    ('rf', rf),\n    ('sgd', pipe_sgd)\n]\n\n# Meta model with gridSearchCV for the hyperparameters\nmeta = LogisticRegression(random_state=42)\n\nstack = StackingClassifier(\n    estimators=base_estimators,\n    final_estimator=meta,\n    cv=5,\n    stack_method='predict_proba',   \n    n_jobs=-1,\n    passthrough=False\n)\nparam_grid = {\n'final_estimator__C': [0.01, 0.1, 1, 10, 100],\n'final_estimator__penalty': ['l1', 'l2'],\n'final_estimator__solver': ['liblinear', 'saga'],\n'final_estimator__max_iter': [1000, 2000]\n}\n\ngs = GridSearchCV(stack, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n\ntrainer = ModelTrainer(gs)\ntrainer.train(X_tr,y_tr)\ntrainer.evaluate(X_val,y_val)\n\nprint(\"Best CV score:\", gs.best_score_)\nprint(\"Best params:\", gs.best_params_)\n\n# ------------------ Evaluate on Test Set -----------------\n\nevaluate_test_set(trainer, selected_features, test_file_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T21:57:35.668759Z","iopub.execute_input":"2025-11-13T21:57:35.669556Z","iopub.status.idle":"2025-11-13T22:55:29.720606Z","shell.execute_reply.started":"2025-11-13T21:57:35.669521Z","shell.execute_reply":"2025-11-13T22:55:29.719703Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}